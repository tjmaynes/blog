<!doctype html><html lang=en-us><head><meta http-equiv=content-security-policy content="default-src 'self' https: 'unsafe-inline' 'unsafe-eval'; worker-src 'self' blob:; connect-src 'self' wss: data:; font-src 'self' https: data:; img-src 'self' https: data:; object-src 'none'"><meta name=generator content="After Dark Hugo"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Drawing Shapes with NAO | TJ Maynes</title><meta name=description content="In this blog post we'll discusses how to 'teach' the NAO robot to draw shapes that it 'sees' using NAOqi (NAO SDK), Python and OpenCV."><meta name=keywords content="python,opencv,school-project"><meta property="og:title" content="Drawing Shapes with NAO"><meta property="og:description" content="In this blog post we'll discusses how to 'teach' the NAO robot to draw shapes that it 'sees' using NAOqi (NAO SDK), Python and OpenCV."><meta property="og:type" content="article"><meta property="og:url" content="/post/drawing-shapes-with-nao/"><meta property="og:image" content="https://source.unsplash.com/collection/983219/2000x1322"><meta property="article:section" content="post"><meta property="article:published_time" content="2015-05-09T12:00:00+01:00"><meta property="article:modified_time" content="2015-05-09T12:00:00+01:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://source.unsplash.com/collection/983219/2000x1322"><meta name=twitter:title content="Drawing Shapes with NAO"><meta name=twitter:description content="In this blog post we'll discusses how to 'teach' the NAO robot to draw shapes that it 'sees' using NAOqi (NAO SDK), Python and OpenCV."><meta property="og:image" content="https://source.unsplash.com/collection/983219/2000x1322"><meta name=referrer content="same-origin"><script integrity="sha512-2t0yyNrUdtn9WGIoBVxq5vtoJQYfoDQDbqRPpOb75f1hiL39DGLdJKDrGP60fBhXfrFeKyVhzWJvHvLgln/ElA==">/*! Fetch Inject v2.0.4 | Copyright (C) Josh Habdas <jhabdas@protonmail.com> (https://habd.as) | @license Zlib */var fetchInject=function(){"use strict";const a=function(g,c,d,e,f,a,b){a=c.createElement(d),b=c.getElementsByTagName(d)[0],a.appendChild(c.createTextNode(e.text)),a.onload=f(e),b?b.parentNode.insertBefore(a,b):c.head.appendChild(a)};return function(f,b){if(!arguments.length)return Promise.reject(new ReferenceError("Failed to execute 'fetchInject': 1 argument required but only 0 present."));if(arguments[0]&&arguments[0].constructor!==Array)return Promise.reject(new TypeError("Failed to execute 'fetchInject': argument 1 must be of type 'Array'."));if(arguments[1]&&arguments[1].constructor!==Promise)return Promise.reject(new TypeError("Failed to execute 'fetchInject': argument 2 must be of type 'Promise'."));const c=[],d=b?[].concat(b):[],e=[];return f.forEach(a=>d.push(window.fetch(a).then(a=>[a.clone().text(),a.blob()]).then(a=>Promise.all(a).then(a=>{c.push({text:a[0],blob:a[1]})})))),Promise.all(d).then(()=>(c.forEach(b=>{e.push({then:c=>{b.blob.type.includes("text/css")?a(window,document,"style",b,c):a(window,document,"script",b,c)}})}),Promise.all(e)))}}()</script><script integrity="sha512-2XlvnxweZhaHgBdCoOK0PoCUWiSfKibb+RCRZNgqLdvbnx0ZH67FDGKQqmpqCerjMJbZFv6fsXgbmJOOA9K+qA==">/*!
 * Copyright (C) 2019  Josh Habdas <jhabdas@protonmail.com>
 *
 * This file is part of After Dark.
 *
 * After Dark is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as published
 * by the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * After Dark is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with this program.  If not, see <https://www.gnu.org/licenses/>.
 */fetchInject(["/js/lazysizes.min.js"])</script><meta title=mod:fractal-forest content="status:enabled"><script async src=../../js/bpgdec8a.js integrity="sha384-8PG0go3BW8hLm63KbTxk/hNcehaoSbrAhKzsmy2Jhs/KY8QdiKKkjhdeyHY/Q/0I
"></script><link rel=canonical href=../../post/drawing-shapes-with-nao/><link rel=icon sizes=any href="data:image/svg+xml,%3Csvg viewBox=%220 0 46 45%22 xmlns=%22http://www.w3.org/2000/svg%22%3E%3Ctitle%3EAfter Dark%3C/title%3E%3Cpath d=%22M.708 45 23 .416 45.292 45H.708zM35 38 23 19 11 38h24z%22 fill=%22%23000%22/%3E%3C/svg%3E"><style>html{font-size:12px}*{box-sizing:border-box;text-rendering:geometricPrecision}body{font-size:1rem;line-height:1.5rem;margin:0;font-family:Menlo,Monaco,Lucida Console,Liberation Mono,DejaVu Sans Mono,Bitstream Vera Sans Mono,Courier New,monospace,serif;word-wrap:break-word}h1,h2,h3,h4,h5,h6{line-height:1.3em}fieldset{border:none;padding:0;margin:0}pre{padding:2rem;margin:1.75rem 0;background-color:#fff;border:1px solid #ccc;overflow:auto}code[class*=language-],pre[class*=language-],pre code{font-weight:100;text-shadow:none;margin:1.75rem 0}a{cursor:pointer;color:#ff2e88;text-decoration:none;border-bottom:1px solid #ff2e88}a:hover{background-color:#ff2e88;color:#fff}.grid{display:-ms-flexbox;display:flex;-ms-flex-wrap:wrap;flex-wrap:wrap}.grid.\-top{-ms-flex-align:start;align-items:flex-start}.grid.\-middle{-ms-flex-align:center;align-items:center}.grid.\-bottom{-ms-flex-align:end;align-items:flex-end}.grid.\-stretch{-ms-flex-align:stretch;align-items:stretch}.grid.\-baseline{-ms-flex-align:baseline;align-items:baseline}.grid.\-left{-ms-flex-pack:start;justify-content:flex-start}.grid.\-center{-ms-flex-pack:center;justify-content:center}.grid.\-right{-ms-flex-pack:end;justify-content:flex-end}.grid.\-between{-ms-flex-pack:justify;justify-content:space-between}.grid.\-around{-ms-flex-pack:distribute;justify-content:space-around}.cell{-ms-flex:1;flex:1;box-sizing:border-box}@media screen and (min-width:768px){.cell.\-1of12{-ms-flex:0 0 8.33333%;flex:0 0 8.33333%}.cell.\-2of12{-ms-flex:0 0 16.66667%;flex:0 0 16.66667%}.cell.\-3of12{-ms-flex:0 0 25%;flex:0 0 25%}.cell.\-4of12{-ms-flex:0 0 33.33333%;flex:0 0 33.33333%}.cell.\-5of12{-ms-flex:0 0 41.66667%;flex:0 0 41.66667%}.cell.\-6of12{-ms-flex:0 0 50%;flex:0 0 50%}.cell.\-7of12{-ms-flex:0 0 58.33333%;flex:0 0 58.33333%}.cell.\-8of12{-ms-flex:0 0 66.66667%;flex:0 0 66.66667%}.cell.\-9of12{-ms-flex:0 0 75%;flex:0 0 75%}.cell.\-10of12{-ms-flex:0 0 83.33333%;flex:0 0 83.33333%}.cell.\-11of12{-ms-flex:0 0 91.66667%;flex:0 0 91.66667%}}@media screen and (max-width:768px){.grid{-ms-flex-direction:column;flex-direction:column}.cell{-ms-flex:0 0 auto;flex:none}}.hack,.hack blockquote,.hack code,.hack em,.hack h1,.hack h2,.hack h3,.hack h4,.hack h5,.hack h6,.hack strong{font-size:1rem;font-style:normal;font-family:Menlo,Monaco,Lucida Console,Liberation Mono,DejaVu Sans Mono,Bitstream Vera Sans Mono,Courier New,monospace,serif}.hack blockquote,.hack code,.hack em,.hack strong{line-height:20px}.hack blockquote,.hack code,.hack footer,.hack h1,.hack h2,.hack h3,.hack h4,.hack h5,.hack h6,.hack header,.hack li,.hack ol,.hack p,.hack section,.hack ul{float:none;margin:0;padding:0}.hack blockquote,.hack h1,.hack ol,.hack p,.hack ul{margin-top:20px;margin-bottom:20px}.hack h1{position:relative;display:inline-block;display:table-cell;padding:20px 0 30px;margin:0;overflow:hidden}.hack h1:after{content:"====================================================================================================";position:absolute;bottom:10px;left:0}.hack h1+*{margin-top:0}.hack h2,.hack h3,.hack h4,.hack h5,.hack h6{position:relative;margin-bottom:1.75rem}.hack h2:before,.hack h3:before,.hack h4:before,.hack h5:before,.hack h6:before{display:inline}.hack h2:before{content:"## "}.hack h3:before{content:"### "}.hack h4:before{content:"#### "}.hack h5:before{content:"##### "}.hack h6:before{content:"###### "}.hack li{position:relative;display:block;padding-left:20px}.hack li:after{position:absolute;top:0;left:0}.hack ul>li:after{content:"-"}.hack ol{counter-reset:a}.hack ol>li:after{content:counter(a)".";counter-increment:a}.hack ol li:nth-child(n+10):after{left:-7px}.hack blockquote{position:relative;padding-left:17px;padding-left:2ch;overflow:hidden}.hack blockquote:after{content:">\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>\A>";white-space:pre;position:absolute;top:0;left:0;line-height:20px}.hack em:after,.hack em:before{content:"*";display:inline}.hack pre code:after,.hack pre code:before{content:""}.hack code{font-weight:700}.hack code:after,.hack code:before{content:"`";display:inline}.hack hr{position:relative;height:20px;overflow:hidden;border:0;margin:20px 0}.hack hr:after{content:"----------------------------------------------------------------------------------------------------";position:absolute;top:0;left:0;line-height:20px;width:100%;word-wrap:break-word}@-moz-document url-prefix(){.hack h1{display:block}}.hack-ones ol>li:after{content:"1."}p{margin:0 0 1.75rem}.container{max-width:70rem}.container,.container-fluid{margin:0 auto;padding:0 1rem}.inner{padding:1rem}.inner2x{padding:2rem}.pull-left{float:left}.pull-right{float:right}.progress-bar{height:8px;opacity:.8;background-color:#ccc;margin-top:12px}.progress-bar.progress-bar-show-percent{margin-top:38px}.progress-bar-filled{background-color:gray;height:100%;transition:width .3s ease;position:relative;width:0}.progress-bar-filled:before{content:"";border:6px solid transparent;border-top-color:gray;position:absolute;top:-12px;right:-6px}.progress-bar-filled:after{color:gray;content:attr(data-filled);display:block;font-size:12px;white-space:nowrap;position:absolute;border:6px solid transparent;top:-38px;right:0;-ms-transform:translateX(50%);transform:translateX(50%)}table{width:100%;border-collapse:collapse;margin:1.75rem 0;color:#778087}table td,table th{vertical-align:top;border:1px solid #ccc;line-height:15px;padding:10px}table thead th{font-size:10px}table tbody td:first-child{font-weight:700;color:#333}.form{width:30rem}.form-group{margin-bottom:1.75rem;overflow:auto}.form-group label{border-bottom:2px solid #ccc;color:#333;width:10rem;display:inline-block;height:38px;line-height:38px;padding:0;float:left;position:relative}.form-group.form-success label{color:#4caf50!important;border-color:#4caf50!important}.form-group.form-warning label{color:#ff9800!important;border-color:#ff9800!important}.form-group.form-error label{color:#f44336!important;border-color:#f44336!important}.form-control{outline:none;border:none;border-bottom:2px solid #ccc;padding:.5rem 0;width:20rem;height:38px;background-color:transparent}.form-control:focus{border-color:#555}.form-group.form-textarea label:after{position:absolute;content:"";width:2px;background-color:#fff;right:-2px;top:0;bottom:0}textarea.form-control{height:auto;resize:none;padding:1rem 0;border-bottom:2px solid #ccc;border-left:2px solid #ccc;padding:.5rem}select.form-control{border-radius:0;background-color:transparent;-webkit-appearance:none;-moz-appearance:none;-ms-appearance:none}.help-block{color:#999;margin-top:.5rem}.form-actions{margin-bottom:1.75rem}.btn{display:-ms-inline-flexbox;display:inline-flex;-ms-flex-align:center;align-items:center;-ms-flex-pack:center;justify-content:center;cursor:pointer;outline:none;padding:.65rem 2rem;font-size:1rem;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:relative;z-index:1}.btn:active{box-shadow:inset 0 1px 3px rgba(0,0,0,.12)}.btn.btn-ghost{border-color:#757575;color:#757575;background-color:transparent}.btn.btn-ghost:focus,.btn.btn-ghost:hover{border-color:#424242;color:#424242;z-index:2}.btn.btn-ghost:hover{background-color:transparent}.btn-block{width:100%;display:-ms-flexbox;display:flex}.btn-default{color:#fff;background-color:#e0e0e0;border:1px solid #e0e0e0;color:#333}.btn-default:focus:not(.btn-ghost),.btn-default:hover{background-color:#dcdcdc;border-color:#dcdcdc}.btn-success{color:#fff;background-color:#4caf50;border:1px solid #4caf50}.btn-success:focus:not(.btn-ghost),.btn-success:hover{background-color:#43a047;border-color:#43a047}.btn-success.btn-ghost{border-color:#4caf50;color:#4caf50}.btn-success.btn-ghost:focus,.btn-success.btn-ghost:hover{border-color:#388e3c;color:#388e3c;z-index:2}.btn-error{color:#fff;background-color:#f44336;border:1px solid #f44336}.btn-error:focus:not(.btn-ghost),.btn-error:hover{background-color:#e53935;border-color:#e53935}.btn-error.btn-ghost{border-color:#f44336;color:#f44336}.btn-error.btn-ghost:focus,.btn-error.btn-ghost:hover{border-color:#d32f2f;color:#d32f2f;z-index:2}.btn-warning{color:#fff;background-color:#ff9800;border:1px solid #ff9800}.btn-warning:focus:not(.btn-ghost),.btn-warning:hover{background-color:#fb8c00;border-color:#fb8c00}.btn-warning.btn-ghost{border-color:#ff9800;color:#ff9800}.btn-warning.btn-ghost:focus,.btn-warning.btn-ghost:hover{border-color:#f57c00;color:#f57c00;z-index:2}.btn-info{color:#fff;background-color:#00bcd4;border:1px solid #00bcd4}.btn-info:focus:not(.btn-ghost),.btn-info:hover{background-color:#00acc1;border-color:#00acc1}.btn-info.btn-ghost{border-color:#00bcd4;color:#00bcd4}.btn-info.btn-ghost:focus,.btn-info.btn-ghost:hover{border-color:#0097a7;color:#0097a7;z-index:2}.btn-primary{color:#fff;background-color:#2196f3;border:1px solid #2196f3}.btn-primary:focus:not(.btn-ghost),.btn-primary:hover{background-color:#1e88e5;border-color:#1e88e5}.btn-primary.btn-ghost{border-color:#2196f3;color:#2196f3}.btn-primary.btn-ghost:focus,.btn-primary.btn-ghost:hover{border-color:#1976d2;color:#1976d2;z-index:2}.btn-group{overflow:auto}.btn-group .btn{float:left}.btn-group .btn-ghost:not(:first-child){margin-left:-1px}.card{border:1px solid #ccc}.card .card-header{color:#333;text-align:center;background-color:#ddd;padding:.5rem 0}.alert{color:#ccc;padding:1rem;border:1px solid #ccc;margin-bottom:1.75rem}.alert-success{color:#4caf50;border-color:#4caf50}.alert-error{color:#f44336;border-color:#f44336}.alert-info{color:#00bcd4;border-color:#00bcd4}.alert-warning{color:#ff9800;border-color:#ff9800}.media:not(:last-child){margin-bottom:1.25rem}.media-left{padding-right:1rem}.media-left,.media-right{display:table-cell;vertical-align:top}.media-right{padding-left:1rem}.media-body{display:table-cell;vertical-align:top}.media-heading{font-size:1.16667rem;font-weight:700}.media-content{margin-top:.3rem}.avatarholder,.placeholder{background-color:#f0f0f0;text-align:center;color:#b9b9b9;font-size:1rem;border:1px solid #f0f0f0}.avatarholder{width:48px;height:48px;line-height:46px;font-size:2rem;background-size:cover;background-position:50%;background-repeat:no-repeat}.avatarholder.rounded{border-radius:33px}.loading{display:inline-block;content:"&nbsp;";height:20px;width:20px;margin:0 .5rem;animation:a .6s infinite linear;border:2px solid #e91e63;border-right-color:transparent;border-radius:50%}.btn .loading{margin-bottom:0;width:14px;height:14px}.btn div.loading{float:left}.alert .loading{margin-bottom:-5px}@keyframes a{0%{transform:rotate(0)}to{transform:rotate(1turn)}}.menu{width:100%}.menu .menu-item{display:block;color:#616161;border-color:#616161}.menu .menu-item.active,.menu .menu-item:hover{color:#000;border-color:#000;background-color:transparent}@media screen and (max-width:768px){.form-group label{display:block;border-bottom:none;width:100%}.form-group.form-textarea label:after{display:none}.form-control{width:100%}textarea.form-control{border-left:none;padding:.5rem 0}pre::-webkit-scrollbar{height:3px}}@media screen and (max-width:480px){.form{width:100%}}.dark-grey{background-color:#181818;color:#ccc}.dark-grey pre{background-color:#181818;padding:0;border:none}.dark-grey pre code{color:#00bcd4}.dark-grey h1 a,.dark-grey h2 a,.dark-grey h3 a,.dark-grey h4 a,.dark-grey h5 a{color:#ccc}.dark-grey code,.dark-grey strong{color:#fff}.dark-grey code{font-weight:100}.dark-grey table{color:#ccc}.dark-grey table td,.dark-grey table th{border-color:#444}.dark-grey table tbody td:first-child{color:#fff}.dark-grey .form-group label{color:#ccc;border-color:rgba(95,95,95,.78)}.dark-grey .form-group.form-textarea label:after{background-color:#181818}.dark-grey .form-control{color:#ccc;border-color:rgba(95,95,95,.78)}.dark-grey .form-control:focus{border-color:#ccc;color:#ccc}.dark-grey textarea.form-control{color:#ccc}.dark-grey .card{border-color:rgba(95,95,95,.78)}.dark-grey .card .card-header{background-color:transparent;color:#ccc;border-bottom:1px solid rgba(95,95,95,.78)}.dark-grey .btn.btn-ghost.btn-default{border-color:#ababab;color:#ababab}.dark-grey .btn.btn-ghost.btn-default:focus,.dark-grey .btn.btn-ghost.btn-default:hover{border-color:#9c9c9c;color:#9c9c9c;z-index:1}.dark-grey .btn.btn-ghost.btn-default:focus,.dark-grey .btn.btn-ghost.btn-default:hover{border-color:#e0e0e0;color:#e0e0e0}.dark-grey .btn.btn-ghost.btn-primary:focus,.dark-grey .btn.btn-ghost.btn-primary:hover{border-color:#64b5f6;color:#64b5f6}.dark-grey .btn.btn-ghost.btn-success:focus,.dark-grey .btn.btn-ghost.btn-success:hover{border-color:#81c784;color:#81c784}.dark-grey .btn.btn-ghost.btn-info:focus,.dark-grey .btn.btn-ghost.btn-info:hover{border-color:#4dd0e1;color:#4dd0e1}.dark-grey .btn.btn-ghost.btn-error:focus,.dark-grey .btn.btn-ghost.btn-error:hover{border-color:#e57373;color:#e57373}.dark-grey .btn.btn-ghost.btn-warning:focus,.dark-grey .btn.btn-ghost.btn-warning:hover{border-color:#ffb74d;color:#ffb74d}.dark-grey .avatarholder,.dark-grey .placeholder{background-color:transparent;border-color:#333}.dark-grey .menu .menu-item{color:#ccc;border-color:rgba(95,95,95,.78)}.dark-grey .menu .menu-item.active,.dark-grey .menu .menu-item:hover{color:#fff;border-color:#ccc}/*!* Copyright (C) 2019 Josh Habdas <jhabdas@protonmail.com>
*
* This file is part of After Dark.
*
* After Dark is free software: you can redistribute it and/or modify
* it under the terms of the GNU Affero General Public License as published
* by the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* After Dark is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU Affero General Public License for more details.
*
* You should have received a copy of the GNU Affero General Public License
* along with this program. If not, see <https://www.gnu.org/licenses/>.*/:root{--screen-size-small:30em}@keyframes intro{0%{opacity:0}100%{opacity:1}}.blur-up.lazyloading{filter:blur(5px);opacity:1;transition:opacity 1s,filter 1.5s}.blur-up.lazyload{opacity:0;filter:blur(10px)}.blur-up.lazyloaded{filter:blur(0);transition:filter 1s}.hack .readmore{margin-bottom:2.2em}.responsive-iframe,.ratio-container{position:relative;padding-bottom:56.25%;padding-top:25px;height:0}.responsive-iframe iframe,.ratio-container>*:not([itemprop=caption]){position:absolute;top:0;left:0;width:100%;height:100%}iframe{border:0}main,footer{animation:intro .3s both;animation-delay:.15s}header:first-of-type+details{margin:20px 0}footer time[datetime$=M]:before{content:"\2013\0020"}body>footer p.muted{margin-bottom:0}@media only screen and (max-width:768px){footer time[datetime$=M]{display:none}}blockquote cite{display:block}blockquote cite::before{content:"\2014\00A0"}:target{filter:brightness(1.2)}:disabled{cursor:not-allowed}.hack li ul{margin:0}.hack ol li{padding-left:27px}.main{padding:20px 10px}input.form-control{border-radius:0;background-color:transparent;-webkit-appearance:none;-moz-appearance:none;-ms-appearance:none}input.form-control,textarea.form-control,select.form-control,.help-block{font-size:initial}@media only screen and (max-width:768px){.help-block{font-size:unset}}html{font-size:13px}.hack .form input,.hack .form textarea,.hack .form button,.hack .form label{font-size:1rem}.hack .alert .highlight:first-of-type .chroma,.hack .card .highlight:first-of-type .chroma,.hack .alert pre:first-of-type,.hack .alert p:first-of-type,.hack .card pre:first-of-type,.hack .card p:first-of-type{margin-top:unset}.hack .alert .highlight:last-of-type .chroma,.hack .card .highlight:last-of-type .chroma,.hack .alert pre:last-of-type,.hack .alert p:last-of-type,.hack .card pre:last-of-type,.hack .card p:last-of-type{margin-bottom:unset}.hack blockquote,.hack blockquote:after{line-height:1.5}.hack figure,.standard figure{margin:unset}.hack figure a{border-bottom:none}.hack figure a:hover{background-color:inherit}article header img{width:100%;border-radius:3px}table td,table th{line-height:inherit}table a{border-bottom:unset}img{max-width:100%}@media only screen and (min-width:768px){html{font-size:16px}.container{max-width:50rem}}@media only screen and (min-width:768px),(-ms-high-contrast:active),(-ms-high-contrast:none){html{margin-left:calc(100vw - 100%)}}/*!* Copyright (C) 2019 Josh Habdas <jhabdas@protonmail.com>
*
* This file is part of After Dark.
*
* After Dark is free software: you can redistribute it and/or modify
* it under the terms of the GNU Affero General Public License as published
* by the Free Software Foundation, either version 3 of the License, or
* (at your option) any later version.
*
* After Dark is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
* GNU Affero General Public License for more details.
*
* You should have received a copy of the GNU Affero General Public License
* along with this program. If not, see <https://www.gnu.org/licenses/>.*/a[rel*=external]::after{content:" " url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 class=%22i-external%22 viewBox=%220 0 32 32%22 width=%2214%22 height=%2214%22 fill=%22none%22 stroke=%22%23ff9800%22 stroke-linecap=%22round%22 stroke-linejoin=%22round%22 stroke-width=%229.38%25%22%3E%3Cpath d=%22M14 9H3V29H23V18M18 4H28V14M28 4 14 18%22/%3E%3C/svg%3E")}nav a.active{background-color:inherit;color:#fff}a[itemprop=url]{color:#ff9800}a[itemprop=url]:hover{color:#fff}.muted,.help-block{opacity:.7}.hack .muted,.hack .help-block{color:#e0e0e0}</style><meta name=theme-color content="#181818"></head><body class="hack dark-grey main container"><header><nav itemscope itemtype=https://schema.org/SiteNavigationElement><meta itemprop=name content="Main Menu"><a itemprop=url href=../../>Home</a>
<a itemprop=url href=../../about/>About</a></nav></header><main><style>{{ -}}.hack header figure[itemtype*=ImageObject]{position:relative}.hack header figure[itemtype*=ImageObject] figcaption{position:absolute;bottom:0;right:0;text-align:right;padding:15px;font-style:oblique;font-size:smaller;mix-blend-mode:soft-light}.hack header figure[itemtype*=ImageObject] [itemprop=headline]{font-weight:700}</style><article itemscope itemtype=https://schema.org/BlogPosting><meta itemprop=name content="Drawing Shapes with NAO"><meta itemprop=description content="In this blog post we'll discusses how to 'teach' the NAO robot to draw shapes that it 'sees' using NAOqi (NAO SDK), Python and OpenCV."><meta itemprop=datePublished content="2015-05-09T12:00:00+01:00"><meta itemprop=dateModified content="2015-05-09T12:00:00+01:00"><meta itemprop=wordCount content="2407"><meta itemprop=image content="https://source.unsplash.com/collection/983219/2000x1322"><meta itemprop=keywords content="python,opencv,school-project,"><header><h1 itemprop="headline name">Drawing Shapes with NAO</h1><p class=muted><svg style="margin-bottom:-3px" class="i-clock" viewBox="0 0 32 32" width="16" height="16" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="6.25%"><circle cx="16" cy="16" r="14"/><path d="M16 8v8l4 4"/></svg><span>12 minute read</span><svg style="margin-bottom:-3px" class="i-edit" viewBox="0 0 32 32" width="16" height="16" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="6.25%"><path d="M30 7 25 2 5 22 3 29l7-2zM21 6l5 5zM5 22l5 5z"/></svg>
Published: <time datetime=2015-05-09T12:00:00+01:00>9 May, 2015</time></p><blockquote itemprop=description>In this blog post we'll discusses how to 'teach' the NAO robot to draw shapes that it 'sees' using NAOqi (NAO SDK), Python and OpenCV.</blockquote></header><div itemprop=articleBody><p>This blog post discusses how to &ldquo;teach&rdquo; the NAO robot to draw shapes that it &ldquo;sees&rdquo; using NAOqi, Python and OpenCV. By the end of this blog post, you should have a better understanding of Canny Edge Detection and using Pixel Position interpolation to map a virual space to Forward Kinematics.</p><p><img src=../../images/blog/nao-bot-1.png alt=1></p><h2 id=background>Background</h2><p>I just graduated with a Computer Science degree and wanted to share my Robotics class project that I&rsquo;m proud of working on. Movies like <a href=https://www.imdb.com/title/tt0371746/>Iron Man</a> and <a href=https://www.imdb.com/title/tt0103064>Terminator 2</a> have inspired me to learn more about Computer Vision and Robotics. So, for my last semester of college, I was pretty excited to enroll in the Robotics course taught by <a href=http://www.cse.usf.edu/~yusun/>Dr. Yu Sun</a>.</p><p>Dr. Sun had some very expensive robots including a programmable industrial &ldquo;arm&rdquo;, the NAO Robot and some homegrown robots. Roughly 70% of Dr. Sun&rsquo;s Robotic course grade came from a semester long group project. <a href=https://www.linkedin.com/in/tommylin1/>Tommy Lin</a>, my classmate, and I decided to team up on the course project. Tommy and I decided that we could learn and implement some Computer Vision and Robotics concepts together using the NAO Robot. For our project, we decided to write software to teach the NAO robot to draw shapes it &ldquo;sees&rdquo; using NAO SDK, Python and OpenCV.</p><h2 id=project-design>Project Design</h2><p>In order to program the NAO robot to draw basic shapes (seen through the camera sensor), some important design decisions needed to be examined at the beginning of this project. With the help of our course Teacher&rsquo;s Assistant, Caitrin Eaton, we decided these design pieces needed to include:</p><ul><li>Setting up a workspace for the NAO robot to physcially work within.</li><li>Understanding and implementing an edge detection alogrithm to identify shapes.</li><li>Mapping and interpolating the detected shapes (as pixel points) to points in the NAO&rsquo;s workspace.</li><li>Debugging and testing how the NAO robot draws smooth lines.</li></ul><h3 id=setting-up-the-physical-workspace>Setting up the Physical Workspace</h3><p><img src=../../images/blog/nao-bot-2.png alt=2></p><p>We decided early on that we were going to use Forward Kinematics to move the NAO arm. Next, we came up with a general solution for describing lines and shapes in the form of a lookup table. The lookup table contains four coordinate positions (found in Figure 2) that make up a bounding area box area for the NAO to draw within. Since we are using the NAO robot&rsquo;s right arm, RArm, each one of the four coordinate positions are a list of six theta values/joint angles (<code>RShoulderPitch</code>, <code>RShoulderRoll</code>, <code>RElbowYaw</code>, <code>RElbowRoll</code>, <code>RWristYaw</code>, <code>RHand</code>).</p><p>Using this lookup table and the NAOqi <code>getAngles</code> function, we will enable the NAO robot to draw the shapes it sees within its workspace.</p><h2 id=project-implementation>Project Implementation</h2><h3 id=edge-detection>Edge Detection</h3><p>In order to implement edge detection using the NAO robot&rsquo;s camera, we first had PIL, Python Imaging Library. PIL allowed us to capture and save the image from the NAO&rsquo;s camera. Next, we read in the captured photo and used OpenCV&rsquo;s Canny Edge Detection function. The Canny Edge Detection algorithm is implemented in following order:</p><ul><li>We read the image created by PIL, called <em>noognagnook.png</em>, from disk by OpenCV&rsquo;s imread function. The /imread/ function loads an image from file.</li><li>The loaded image is now converted to black and white using OpenCV&rsquo;s /cvtColor/ function. The /cvtColor/ function coverts an image from one color space to another.</li><li>The black and white image is now blurred using OpenCV&rsquo;s /GaussianBlur/ function. The black and white image is blurred because we do not want any extra noise or else that noise will show up as a line in the edge detection. The /GaussianBlur/ function blurs an image using a gaussian filter.</li><li>The black and white blurred image is passed to OpenCV&rsquo;s Canny function. The Canny function creates a mask of thresholds/bright lines that represent our shapes seen by the NAO robot.</li><li>The canny image is saved to a file for referencing/debugging.</li><li>The canny image is now passed to a function called /findContours/. The /findContours/ function returns a sets of Numpy arrays of pixel positions that make up each contour found in an image.</li><li>For each contour found, we take a smaller number of points that it will take to make that contour by using OpenCV&rsquo;s /approxPolyDP/. The /approxPolyDP/ function uses an alogrithm called <a href=https://en.wikipedia.org/wiki/Ramer%E2%80%93Douglas%E2%80%93Peucker_algorithm>Douglas-Peucker algorithm</a> that will approximate a curve or a polygon with another curve/polygon with less vertices so that the distance between them is less or equal to the specified precision.</li><li>Allow the NAO robot to draw a shape using the approximate number of points found at a current contour that creates a polygon.</li></ul><p>Lots of testing was done to make sure that we were using the approriate number of points and the correct points to draw from. Now that we have edge detection setup properly, we can now interpolate the detected pixel position to our workspace by using a lookup table and bilinear interpolation.</p><p><img src=../../images/blog/nao-bot-3.png alt=3></p><h2 id=pixel-position-interpolation>Pixel Position Interpolation</h2><p>In order to interpolate the pixel positions found, we first had to setup a function called <em>lookup_table</em> to pass our desired pixel positions to and return a list of lists of theta values.</p><p>The lookup table created is a matrix of size: 640 columns by 460 rows (pixels from the camera sensor generated image). Next, we had to manually get our four bounding box points by setting the NAO&rsquo;s right arm stiffness to zero and calling <code>getAngles</code>, from the NAOqi API, on the specified grid coordinate. The four specified grid coordinates included: grid[0][0], grid[640][0], grid[0][460], and grid[640][460]. In each of the four specified grid coordinates, there contains a list of six theta values that represent how the NAO&rsquo;s right arm is to get the specified position in its workspace. Once we have our setup our lookup table, we can now move on to mapping the pixels to the specific grid positions via bilinear interpolation.</p><p>The purpose of interpolating the detected pixel positions is to get the theta values needed for the NAO to travel to each desired pixel position needed to draw the desired shape. We will interpolate the theta values desired by comparing their respective pixel position to the four bounded pixel positions in the workspace. We can achieve this by creating a function called <code>bilinear_interpolation</code>, whose algorithm is based on a mathematical formula called Bilinear Interpolation. Using the following algorithm we can create a list of pixel position theta values called path for the NAO to travel to:</p><ul><li>We create a list called path. This list will be used as the final output of the list of lists of theta values needed for the NAO robot to draw a desired shape to.</li><li>Create a variable called <em>go_back_to_start</em> which will record the first pixel position. This pixel position will be used as the last point for the NAO to draw to.</li><li>For each set of points and for each point of those set of points, append the result calculated by the <code>bilinear_interpolation</code> function. The <code>bilinear_interpolation</code> function is passed three arguments: x-coordinate of the current point, y-coordinate of the current point, and a list of the bounding positions (which contains a list of theta values).</li><li>The <code>bilinear_interpolation</code> function will return a list of six theta values that will specify how the NAO will motion the current pixel position.</li><li>This loop continues until we have all the desired lists of pixel position theta values.</li><li>The <code>lookup_table</code> function returns a path list containing a list of all the interpolated pixel position values (each of which contains a list of six theta values).</li></ul><p>Now that we have a path for the NAO robot, we can use this path to create the shape desired. We can create the shape desired by simply looping through each point in the path list. Next, we pass the effector name (/RArm/), the current point in the path, and a specified speed (0.3 seconds) to the /setAngles/ function (from the NAOqi function). The setAngles function will take a set of theta values and a specified effector (like the right arm) and perform a motion trajectory to the desired position via the set of theta values.</p><p><img src=../../images/blog/nao-bot-4.png alt=4></p><h2 id=testing-and-feedback>Testing and Feedback</h2><p>To effectively start testing the NAO&rsquo;s ability to draw shapes, we had to make sure the following was working accordingly: image processing was return the correct pixel positions desired; the bilinear interpolation of the each (correct) pixel position found was calculated correctly; and the motion trajectory of the path generated was working properly. Assuming that the previously mentioned list was in fact working properly, then we would be able to debug and test for smoother line drawing. However, over the course of the semester, we encountered practically every issue that could occur in the previously mentioned list. Specifically, a majority of the tests completed were based on debugging issues we encountered from image processing and interpolation issues from our motion trajectory algorithm. Also, issues such as how the NAO gripped the marker affected how well the seen shapes were drawn.</p><p>We were having issues with choosing the right set of pixel positions for the NAO robot to interpolate from and draw from. Particulary, we had issues with the data structure created by OpenCV to hold the pixel position data returned as an Numpy array of lists of coordinate values. When we tried to have NAO draw based on the pixel positions that we were reading in, the NAO would draw all sorts of various lines that were not coherient to the image being seen. We started debugging this issue by working backwards on the issue by making sure that the bilinear interpolation function was working properly. Using print statements, we found that the points being read in were properly. This was proven by cross checking the returned list of interpolated pixel position theta values list were within the bounds of the theta values of each corner pixel position. Next, we tested the points that were being passed into the lookup_table function. At first the points being passed were the entire set of contours found in the image. This is not necessary a problem, unless the NAO picks up other contours (like noise) found in the image. After minor tweaking the area that the NAO looks at, we were able to get a much cleaner set of contours that made up a single shape for the NAO to draw from. Finally, we tested which of the set of points we wanted to draw. At first, we used the entire set of contours found in the image, however ultimately we decided not to draw 2000 positions in the NAO&rsquo;s workspace. Instead, we decided to use the approximate number of points that will make a polygon found at a current contour. This proved to work as needed since we were able to draw four points in the NAO&rsquo;s workspace as opposed to 2000 points.</p><p>The issues that caused the motion trajectory problems were from not fully understanding the ALMotion API (part of NAOqi API). Early on, we started by using the positionInterpolation function, which moves end-effectors to given positions and orientations over a period of time. This was a mistake from the very start since we were trying to apply angles to a position interpolation. This issue stemed from the fact that we did not fully understand the NAOqi API. Next, we tried to use the angleInterpolation function, which interpolates one or multiple joints to a target angle or along timed trajectories. This also proved to be a complicated mistake that we never fully realized why the issues occured. Basically, no matter what the shape was seen, the NAO would make the same right arm motions. Finally, we figured out a much simplier solution by looping through each point in list of points and calling the setAngles function to draw to each position. This proved to be the easiest to setup and ultimately made the best looking shapes. We were able to prove this by feeding the setAngles function the bounding coordinates found, which should have the NAO robot travel to the specific bounding positions. The setAngles function caused the NAO to smoothly go to each corner position in its bounding box.</p><p>Finally, there were problems with how well the NAO robot was drawing the shapes that it had seen. The main reason behind these issues was that the NAO had a difficult time gripping the marker that was being used to draw the shape seen. Other reasons also include the friction and force, from the speed of the NAO&rsquo;s setAngle execution, caused the marker to move around slightly creating curved lines. We were able to fix a majority of these problems by making sure the NAO&rsquo;s grip on the marker was more stable by adding another rubberband around its hand.</p><p>#+CAPTION: Figure 6 - Final video of the NAO&rsquo;s journey to discovering the power of drawing shapes.<div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube-nocookie.com/embed/1_-gUEW5GuY style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div></p><h2 id=conclusion>Conclusion</h2><p>Given a semesters worth of time, we were able to have the NAO robot draw a somewhat decent interpretation of the shape it sees. We learned quite a bit about robotics from this project including properly setting up motion trajectories, understanding and using motion interpolation and bilinear interpolation for pixel positions found to the workspace, and how to decide the various approaches that can be used to solve a robotics related problem. If we had more time, we would liked to have the NAO robot draw different shapes/objects dependent in the NAO&rsquo;s workspace. Also, we would have liked to be able to tweak the motion trajectory algorithm in order to have smoother lines drawn. This could have potentially been solved by using a marker that had a prismatic joint for its tip, so that there would be little friction between the paper and the marker (no jerkiness between each angle position drawn). Also, it could have been pretty cool to if the NAO robot could draw, based on our current codebase, other objects like trees, cars, houses, etc.</p><p>We would like to thank Caitrin Eaton for all her help and support for making our progress possible. Caitrin helped us understand bilinear interpolation, how to define the NAO&rsquo;s workspace, and did an incredible job explaining other things along the way. Also, we would like to thank Garfield Huang for his help teaching us about the various ways the NAO operates. Finally, we would like to thank Dr. Yu Sun for allowing us to work on this project this semester! Dr. Sun&rsquo;s research can be found <a href=http://www.cse.usf.edu/~yusun/>here</a>!</p><h3 id=sources>Sources</h3><ul><li><a href=http://doc.aldebaran.com/1-14/naoqi/motion/control-joint-api.html#ALMotionProxy::setAngles__AL::ALValueCR.AL::ALValueCR.floatCR>Aldebaran - setAngles function</a></li><li><a href=http://doc.aldebaran.com/1-14/naoqi/motion/control-joint-api.html#ALMotionProxy::getAngles__AL::ALValueCR.bCR>Aldebaran - getAngles function</a></li><li><a href=http://en.wikipedia.org/wiki/Bilinear_interpolation>Wikipedia - Bilinear Interpolation</a></li><li><a href=http://stackoverflow.com/questions/8661537/how-to-perform-bilinear-interpolation-in-python>StackOverflow - How to perform bilinear interpolation in Python</a></li><li><a href=http://docs.opencv.org/doc/tutorials/imgproc/imgtrans/canny_detector/canny_detector.html>OpenCV - Canny Edge Detector</a></li><li><a href="http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=findcontours#findcontours">OpenCV - findContours</a></li><li><a href="http://docs.opencv.org/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html?highlight=cv2.approxpolydp#cv2.approxPolyDP">OpenCV - approxPolyDP</a></li></ul></div><footer><hr><p>Published
by <span itemprop=author>TJ Maynes</span>
<time itemprop=datePublished datetime=2015-05-09T12:00:00+01:00>9 May, 2015</time>
in <span itemprop=articleSection><a href=../../categories/automation/>automation</a> and <a href=../../categories/python/>python</a></span>
and tagged <a rel=tag href=../../tags/opencv/>opencv</a>, <a rel=tag href=../../tags/python/>python</a> and <a rel=tag href=../../tags/school-project/>school-project</a>
using <span itemprop=wordCount>2407</span> words.</p></footer></article></main><footer><small class=muted></small></footer></body></html>